{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bikeshare_2023.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info and dtypes of the dataframe\n",
    "print(\"Info of the DataFrame:\\n\", '\\n')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_before = df.nunique()\n",
    "print(\"Unique values before conversion:\\n\", unique_values_before, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially execute some data cleaning at this stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with data for all of 2023\n",
    "\n",
    "# weekend yes / no\n",
    "# --> have for each season option to further differentiate between weekend yes, or no\n",
    "\n",
    "# aggregate by season (again 90 days balance) \n",
    "# --> allows me to see changes from one season to the next\n",
    "# --> balancing only problem in certain seasons (summer!?)\n",
    "# --> have menu to shift between seasons (starting point: summer or whichever season effect is the strongest)\n",
    "\n",
    "# then integrate into analysis member-type\n",
    "# --> have for each season option to further differentiate between all, casual-only, member-only\n",
    "\n",
    "# disregard electric / classic bike\n",
    "\n",
    "# if I still have time\n",
    "# what is close-by at main underbalance or overbalance location\n",
    "# commuter station locations along main roads to north do no seem to have a problem (members only, same day return!?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to capacity \n",
    "# make calculation for high-frequency stations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA w/o member type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude docked bikes if the column exists\n",
    "if 'rideable_type' in df.columns:\n",
    "    df = df[df['rideable_type'] != 'docked_bike']\n",
    "\n",
    "# check count of start stations per day\n",
    "df_2 = df.copy() # to make sure any changes in df_full will not automatically affect df_full_2\n",
    "\n",
    "# Create a new dataframe with unique dates and stations\n",
    "unique_dates = df_2['date'].unique()\n",
    "unique_stations = df_2['end_station_name'].unique()\n",
    "\n",
    "# Extract unique end_station_name with their corresponding latitudes and longitudes\n",
    "unique_stations_lat_lng = df_2[['end_station_name', 'end_lat', 'end_lng']].drop_duplicates().rename(columns={'end_station_name': 'STATION', 'end_lat': 'LAT', 'end_lng': 'LNG'})\n",
    "\n",
    "# Create df_2_unique with unique dates and stations\n",
    "df_2_unique = pd.MultiIndex.from_product([unique_dates, unique_stations], names=['DATE', 'STATION']).to_frame(index=False)\n",
    "\n",
    "# Add the 'weekday' column directly behind each date\n",
    "df_2_unique = df_2_unique.merge(df_2[['date', 'weekday']].drop_duplicates(), left_on='DATE', right_on='date', how='left', suffixes=('', '_weekday'))\n",
    "df_2_unique.rename(columns={'weekday': 'WEEKDAY'}, inplace=True)\n",
    "\n",
    "# Add the 'season' column directly behind each date\n",
    "df_2_unique = df_2_unique.merge(df_2[['date', 'season']].drop_duplicates(), left_on='DATE', right_on='date', how='left', suffixes=('', '_season'))\n",
    "df_2_unique.rename(columns={'season': 'SEASON'}, inplace=True)\n",
    "\n",
    "# Merge the latitudes and longitudes into df_2_unique\n",
    "df_2_unique = df_2_unique.merge(unique_stations_lat_lng, left_on='STATION', right_on='STATION', how='left')\n",
    "\n",
    "# Calculate COUNT_PICKUP and COUNT_RETURN\n",
    "count_pickup = df_2.groupby(['date', 'start_station_name']).size().reset_index(name='COUNT_PICKUP')\n",
    "count_return = df_2.groupby(['date', 'end_station_name']).size().reset_index(name='COUNT_RETURN')\n",
    "\n",
    "# Merge the counts into df_2_unique\n",
    "df_2_unique = df_2_unique.merge(count_pickup, left_on=['DATE', 'STATION'], right_on=['date', 'start_station_name'], how='left', suffixes=('', '_pickup'))\n",
    "df_2_unique = df_2_unique.merge(count_return, left_on=['DATE', 'STATION'], right_on=['date', 'end_station_name'], how='left', suffixes=('', '_return'))\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_2_unique['COUNT_PICKUP'] = df_2_unique['COUNT_PICKUP'].fillna(0)\n",
    "df_2_unique['COUNT_RETURN'] = df_2_unique['COUNT_RETURN'].fillna(0)\n",
    "\n",
    "# Simplify the overview to four columns\n",
    "df_2_unique = df_2_unique[['DATE', 'WEEKDAY', 'SEASON', 'STATION', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN']]\n",
    "\n",
    "# Add a new column called 'BALANCE' at the end which by line subtracts COUNT_RETURN from COUNT_PICKUP\n",
    "df_2_unique['BALANCE'] = df_2_unique['COUNT_RETURN'] - df_2_unique['COUNT_PICKUP']\n",
    "\n",
    "# Remove all rows with empty value in column 'STATION'\n",
    "df_2_unique = df_2_unique.dropna(subset=['STATION'])\n",
    "\n",
    "# Add the 'week_number' column, rename it to 'WEEK_NR', and place it behind the 'DATE' column\n",
    "df_2_unique = df_2_unique.merge(df_2[['date', 'week_number']].drop_duplicates(), left_on='DATE', right_on='date', how='left')\n",
    "df_2_unique.rename(columns={'week_number': 'WEEK_NR'}, inplace=True)\n",
    "df_2_unique = df_2_unique[['DATE', 'WEEK_NR', 'WEEKDAY', 'SEASON', 'STATION', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN', 'BALANCE']]\n",
    "\n",
    "df_2_unique\n",
    "\n",
    "# Questions: 3000 rows were added when LAT and LNG were added as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by station and week number the cumulative BALANCE, COUNT_PICKUP, and COUNT_RETURN for all days\n",
    "df_cumulative_balance = df_2_unique.groupby(['STATION', 'WEEK_NR']).agg({\n",
    "    'BALANCE': 'sum',\n",
    "    'COUNT_PICKUP': 'sum',\n",
    "    'COUNT_RETURN': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the BALANCE column to CUMULATIVE_BALANCE\n",
    "df_cumulative_balance.rename(columns={'BALANCE': 'CUMULATIVE_BALANCE'}, inplace=True)\n",
    "\n",
    "# Reorder columns to place 'CUMULATIVE_BALANCE' as the last column\n",
    "df_cumulative_balance = df_cumulative_balance[['STATION', 'WEEK_NR', 'COUNT_PICKUP', 'COUNT_RETURN', 'CUMULATIVE_BALANCE']]\n",
    "\n",
    "# Sort the results by STATION and WEEK_NR\n",
    "df_cumulative_balance = df_cumulative_balance.sort_values(by=['STATION', 'WEEK_NR'])\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the specified station\n",
    "station_records = df_cumulative_balance[df_cumulative_balance['STATION'] == '11th & Kenyon St NW']\n",
    "\n",
    "# Display the records\n",
    "station_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the specified station\n",
    "station_records = df_cumulative_balance[df_cumulative_balance['STATION'] == '14th St & Rhode Island Ave NW']\n",
    "\n",
    "# Display the records\n",
    "station_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '14th & Rhode Island Ave NW'\n",
    "# Filter the DataFrame for the specified station\n",
    "station_records = df_cumulative_balance[df_cumulative_balance['STATION'] == '14th & Rhode Island Ave NW']\n",
    "\n",
    "# Display the records\n",
    "station_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the two stations\n",
    "stations_to_merge = ['14th & Rhode Island Ave NW', '14th St & Rhode Island Ave NW']\n",
    "filtered_stations = df_cumulative_balance[df_cumulative_balance['STATION'].isin(stations_to_merge)]\n",
    "\n",
    "# Group by WEEK_NR and sum the values for the two stations\n",
    "merged_values = filtered_stations.groupby('WEEK_NR').agg({\n",
    "    'COUNT_PICKUP': 'sum',\n",
    "    'COUNT_RETURN': 'sum',\n",
    "    'CUMULATIVE_BALANCE': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Add the merged values to the station '14th St & Rhode Island Ave NW'\n",
    "merged_values['STATION'] = '14th St & Rhode Island Ave NW'\n",
    "\n",
    "# Remove the original records for the two stations\n",
    "df_cumulative_balance = df_cumulative_balance[~df_cumulative_balance['STATION'].isin(stations_to_merge)]\n",
    "\n",
    "# Append the merged values back to the DataFrame\n",
    "df_cumulative_balance = pd.concat([df_cumulative_balance, merged_values], ignore_index=True)\n",
    "\n",
    "# Ensure 'LAT' and 'LNG' values for '14th St & Rhode Island Ave NW' are retained\n",
    "df_cumulative_balance.loc[df_cumulative_balance['STATION'] == '14th St & Rhode Island Ave NW', ['LAT', 'LNG']] = [first_lat, first_lng]\n",
    "\n",
    "# Delete all rows for station '14th & Rhode Island Ave NW'\n",
    "df_cumulative_balance = df_cumulative_balance.drop(df_cumulative_balance[df_cumulative_balance['STATION'] == '14th & Rhode Island Ave NW'].index)\n",
    "\n",
    "# Filter and display the updated DataFrame for '14th St & Rhode Island Ave NW'\n",
    "df_cumulative_balance[df_cumulative_balance['STATION'] == '14th St & Rhode Island Ave NW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for different values in 'LAT' or 'LNG' for the same 'STATION'\n",
    "lat_lng_check = df_2_unique.groupby('STATION').agg({'LAT': pd.Series.nunique, 'LNG': pd.Series.nunique})\n",
    "stations_with_multiple_lat_lng = lat_lng_check[(lat_lng_check['LAT'] > 1) | (lat_lng_check['LNG'] > 1)].index\n",
    "\n",
    "# Amend all records for the same 'STATION' to the first found values\n",
    "for station in stations_with_multiple_lat_lng:\n",
    "    first_lat = df_2_unique.loc[df_2_unique['STATION'] == station, 'LAT'].dropna().iloc[0]\n",
    "    first_lng = df_2_unique.loc[df_2_unique['STATION'] == station, 'LNG'].dropna().iloc[0]\n",
    "    df_2_unique.loc[df_2_unique['STATION'] == station, 'LAT'] = first_lat\n",
    "    df_2_unique.loc[df_2_unique['STATION'] == station, 'LNG'] = first_lng\n",
    "\n",
    "df_cumulative_balance = df_cumulative_balance.merge(df_2_unique[['STATION', 'WEEK_NR', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN']].drop_duplicates(), on='STATION', how='left')\n",
    "df_cumulative_balance = df_2_unique.groupby(['STATION', 'WEEK_NR', 'LAT', 'LNG'])[['COUNT_PICKUP', 'COUNT_RETURN', 'BALANCE']].sum().reset_index().sort_values(by='BALANCE')\n",
    "df_cumulative_balance.rename(columns={'BALANCE': 'CUMULATIVE_BALANCE'}, inplace=True)\n",
    "df_cumulative_balance = df_cumulative_balance[['STATION', 'WEEK_NR', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN', 'CUMULATIVE_BALANCE']]\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a histogram plot using seaborn\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.histplot(data=df_cumulative_balance, x='CUMULATIVE_BALANCE', bins=30, kde=True)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Weekly distribution of Cumulative Balance by Station')\n",
    "plt.xlabel('Cumulative Balance')\n",
    "plt.ylabel('Count of Weekly Station Records')\n",
    "\n",
    "# Add values on top of each bar, further away from the top end\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height() + 5.0), ha='center', va='baseline')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cumulative_balance[df_cumulative_balance['CUMULATIVE_BALANCE'] > 450]\n",
    "# equates to 111 rows if criteria is set to +90 (= +1/day over 90 days)\n",
    "# equates to 72 rows if criteria is set to +180 (= +2/day over 90 days)\n",
    "# equates to 55 rows if criteria is set to +270 (= +3/day over 90 days)\n",
    "# equates to 46 rows if criteria is set to +360 (= +4/day over 90 days)\n",
    "# equates to 32 rows if criteria is set to +450 (= +5/day over 90 days)\n",
    "\n",
    "\n",
    "df_cumulative_balance[df_cumulative_balance['CUMULATIVE_BALANCE'] < -450]\n",
    "# equates to 111 rows if criteria is set to -90 (= -1/day over 90 days)\n",
    "# equates to 72 rows if criteria is set to -180 (= -2/day over 90 days)\n",
    "# equates to 53 rows if criteria is set to -270 (= -3/day over 90 days)\n",
    "# equates to 37 rows if criteria is set to -360 (= -4/day over 90 days)\n",
    "# equates to 27 rows if criteria is set to -450 (= -5/day over 90 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file capacity_data.csv\n",
    "df_capacity = pd.read_csv('capacity_data.csv', sep=';')\n",
    "df_capacity.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_balance = df_cumulative_balance.drop(df_cumulative_balance[df_cumulative_balance['STATION'] == '14th & Rhode Island Ave NW'].index)\n",
    "\n",
    "# compare row values in column start_station_name of dataframe df_capacity with row values in column STATION of dataframe df_cumulative_balance and print the mis-matches\n",
    "# Compare STATION in df_cumulative_balance with start_station_name in df_capacity and print mismatches\n",
    "mismatches = df_cumulative_balance[~df_cumulative_balance['STATION'].isin(df_capacity['start_station_name'])]\n",
    "# print(\"Mismatches:\\n\", mismatches)\n",
    "mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to code section above execute code to show both stations only in df_cumulative\n",
    "# filtered_stations1 = df_cumulative_balance[df_cumulative_balance['STATION'].isin(['3rd & M St SE', '3rd & M St NE'])]\n",
    "# 14 min apart,i.e. not same stations\n",
    "# filtered_stations1 = df_cumulative_balance[df_cumulative_balance['STATION'].isin(['3rd & N St NE', '3rd & M St NE'])]\n",
    "# filtered_stations1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE CAPACITY DATA WITH CUMULATIVE BALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_cumulative_balance with df_capacity on the station name\n",
    "df_cumulative_balance = df_cumulative_balance.merge(df_capacity, left_on='STATION', right_on='start_station_name', how='left')\n",
    "\n",
    "# Rename the 'capacity' column to 'CAPACITY'\n",
    "df_cumulative_balance.rename(columns={'capacity': 'CAPACITY'}, inplace=True)\n",
    "\n",
    "# Drop the redundant 'start_station_name' column\n",
    "df_cumulative_balance.drop(columns=['start_station_name'], inplace=True)\n",
    "\n",
    "# Reorder columns to keep 'COUNT_PICKUP' and 'COUNT_RETURN' behind 'LNG'\n",
    "columns_order = ['STATION', 'WEEK_NR', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN', 'CUMULATIVE_BALANCE', 'CAPACITY']\n",
    "df_cumulative_balance = df_cumulative_balance[columns_order]\n",
    "\n",
    "df_cumulative_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stations for each capacity value\n",
    "capacity_counts = df_cumulative_balance['CAPACITY'].value_counts().sort_index()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(capacity_counts, labels=capacity_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Stations by Capacity')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used OpenOfficeCalc to see that 87% stations have capacity up to 21days, 15 days limit would only cover 56%\n",
    "\n",
    "Development of calculation logic for imbalance categories:\n",
    "1. Imbalance starts when whole station is full or empty\n",
    "2. Hence, if I set limit at 21 bikes (+/-) then I have an accurate measurement (covers 87% of stations)\n",
    "3. Even better way would be to calculate imbalance for each station capacity category individually () "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION OF IMBALANCE FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate an 'IMBALANCE FACTOR' for each row in df_cumulative_balance. Take value in 'CUMULATIVE_BALANCE' (weekly), \n",
    "# then take the result and divide it by the value in column 'CAPACITY' in same. \n",
    "# Result of this calculation should be put as float with one decimal in the new column 'IMBALANCE FACTOR' \n",
    "df_cumulative_balance['IMBALANCE_FACTOR'] = (df_cumulative_balance['CUMULATIVE_BALANCE'] / df_cumulative_balance['CAPACITY']).round(1)\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_balance['IMB_FAC_CATEGORY'] = df_cumulative_balance['IMBALANCE_FACTOR'].apply(\n",
    "    lambda x: 'too_few' if x < -0.5 else ('balanced' if x <= 0.5 else 'too_many')\n",
    ")\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the color scheme\n",
    "# Count the number of stations in each IMB_FAC_CATEGORY\n",
    "imb_fac_category_counts = df_cumulative_balance['IMB_FAC_CATEGORY'].value_counts()\n",
    "\n",
    "# Plot the distribution as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "bars = ax.bar(imb_fac_category_counts.index, imb_fac_category_counts.values)\n",
    "\n",
    "# Apply colors to each bar based on its category\n",
    "for bar, category in zip(bars, imb_fac_category_counts.index):\n",
    "    color_scheme = {'balanced': 'lightgreen', 'too_few': 'lightcoral', 'too_many': 'lightblue'}\n",
    "    bar.set_color(color_scheme[category])\n",
    "\n",
    "plt.title('Distribution of Imbalance-Factor categories')\n",
    "plt.xlabel('Imbalance-Factor category')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add values on top of each bar, further away from the top end\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height() + 5.0), ha='center', va='baseline')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stations in each IMB_FAC_CATEGORY\n",
    "imb_fac_category_counts = df_cumulative_balance['IMB_FAC_CATEGORY'].value_counts()\n",
    "\n",
    "# Plot the distribution as a pie chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "imb_fac_category_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=['lightgreen', 'lightcoral', 'lightblue'])\n",
    "plt.title('Distribution of Imbalance-Factor categories')\n",
    "plt.ylabel('')  # Hide the y-label\n",
    "\n",
    "# Add a legend with the counts\n",
    "legend_labels = [f'{category}: {count}' for category, count in imb_fac_category_counts.items()]\n",
    "plt.legend(legend_labels, loc='upper left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION OF TURNOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce new calculation\n",
    "df_cumulative_balance['TURNOVER'] = ((df_cumulative_balance['COUNT_PICKUP'] / 7) / df_cumulative_balance['CAPACITY']).round(1)\n",
    "df_cumulative_balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histplot using count of stations on y-axis and turnover on x-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df_cumulative_balance, x='TURNOVER', bins=30, kde=True)\n",
    "plt.xlabel('Turnover')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.title('Distribution of Turnover Across Stations')\n",
    "\n",
    "# Add values on top of each bar, further away from the top end\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height() + 5.0), ha='center', va='baseline')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only records with TURNOVER >= 1.5\n",
    "df_filtered = df_cumulative_balance[df_cumulative_balance['TURNOVER'] >= 1.5]\n",
    "\n",
    "# Create a histplot using count of stations on y-axis and turnover on x-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df_filtered, x='TURNOVER', bins=30, kde=True)\n",
    "plt.xlabel('Turnover')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.title('Distribution of Turnover Across Stations (TURNOVER >= 1.5)')\n",
    "\n",
    "# Add values on top of each bar, further away from the top end\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height() + 1.0), ha='center', va='baseline')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_turnover(turnover):\n",
    "    if turnover > 2:\n",
    "        return 'highly-utilized'\n",
    "    elif 0.33 <= turnover <= 2:\n",
    "        return 'well-utilized'\n",
    "    else:\n",
    "        return 'under-utilized'\n",
    "\n",
    "df_cumulative_balance['TO_CATEGORY'] = df_cumulative_balance['TURNOVER'].apply(categorize_turnover)\n",
    "df_cumulative_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order and color scheme\n",
    "category_order = ['highly-utilized', 'well-utilized', 'under-utilized']\n",
    "category_colors = {\n",
    "    'highly-utilized': 'darkgreen',\n",
    "    'well-utilized': 'lightgreen',\n",
    "    'under-utilized': 'lightblue',\n",
    "}\n",
    "\n",
    "# Count the number of stations in each turnover category\n",
    "category_counts = df_cumulative_balance['TO_CATEGORY'].value_counts().reindex(category_order)\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140, colors=[category_colors[cat] for cat in category_order])\n",
    "plt.title('Distribution of Stations by Turnover Category')\n",
    "\n",
    "# Add a legend with the counts\n",
    "legend_labels = [f'{category}: {count}' for category, count in category_counts.items()]\n",
    "plt.legend(legend_labels, loc='upper left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION OF CROSS-CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build cross-category\n",
    "df_cumulative_balance['TO_IMB_CATEGORY'] = df_cumulative_balance['TO_CATEGORY'] + '__' + df_cumulative_balance['IMB_FAC_CATEGORY']\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the categories for the x and y axes\n",
    "to_categories = ['under-utilized', 'well-utilized', 'highly-utilized']\n",
    "imb_fac_categories = ['too_few', 'balanced', 'too_many']\n",
    "\n",
    "# Create a DataFrame to store the counts\n",
    "counts = pd.DataFrame(0, index=imb_fac_categories, columns=to_categories)\n",
    "\n",
    "# Count the number of stations in each cross-category\n",
    "for to_cat in to_categories:\n",
    "    for imb_fac_cat in imb_fac_categories:\n",
    "        counts.loc[imb_fac_cat, to_cat] = df_cumulative_balance[\n",
    "            (df_cumulative_balance['TO_CATEGORY'] == to_cat) & \n",
    "            (df_cumulative_balance['IMB_FAC_CATEGORY'] == imb_fac_cat)\n",
    "        ].shape[0]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Define the color scheme for each quadrant\n",
    "color_scheme = {\n",
    "    ('too_many', 'under-utilized'): 'lightblue',\n",
    "    ('too_many', 'well-utilized'): 'blue',\n",
    "    ('too_many', 'highly-utilized'): 'darkblue',\n",
    "    ('balanced', 'under-utilized'): 'lightgreen',\n",
    "    ('balanced', 'well-utilized'): 'green',\n",
    "    ('balanced', 'highly-utilized'): 'darkgreen',\n",
    "    ('too_few', 'under-utilized'): 'lightcoral',\n",
    "    ('too_few', 'well-utilized'): 'red',\n",
    "    ('too_few', 'highly-utilized'): 'darkred'\n",
    "}\n",
    "\n",
    "# Create a scatter plot with circle sizes based on the counts and fixed color scheme\n",
    "for i, imb_fac_cat in enumerate(imb_fac_categories):\n",
    "    for j, to_cat in enumerate(to_categories):\n",
    "        count = counts.loc[imb_fac_cat, to_cat]\n",
    "        color = color_scheme.get((imb_fac_cat, to_cat), 'white')  # Use 'white' for no values\n",
    "        ax.scatter(j, i, s=count*10*2.0, alpha=0.6, edgecolors='w', color=color)  # Increase size by 25%\n",
    "        ax.text(j, i, count, ha='center', va='center', color='black')\n",
    "\n",
    "# Set the x and y axis labels\n",
    "ax.set_xticks(range(len(to_categories)))\n",
    "ax.set_xticklabels(to_categories)\n",
    "ax.set_yticks(range(len(imb_fac_categories)))\n",
    "ax.set_yticklabels(imb_fac_categories)\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xlabel('Turnover')\n",
    "ax.set_ylabel('Imbalance')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Station categorization\\n based on Turnover & Imbalance')\n",
    "\n",
    "# Adjust the x and y limits to add padding\n",
    "ax.set_xlim(-0.5, len(to_categories) - 0.5)\n",
    "ax.set_ylim(-0.5, len(imb_fac_categories) - 0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the categories for the x and y axes\n",
    "to_categories = ['under-utilized', 'well-utilized', 'highly-utilized']\n",
    "imb_fac_categories = ['too_few', 'balanced', 'too_many']\n",
    "\n",
    "# Create a DataFrame to store the counts\n",
    "counts = pd.DataFrame(0, index=imb_fac_categories, columns=to_categories)\n",
    "\n",
    "# Count the number of stations in each cross-category\n",
    "for to_cat in to_categories:\n",
    "    for imb_fac_cat in imb_fac_categories:\n",
    "        counts.loc[imb_fac_cat, to_cat] = df_cumulative_balance[\n",
    "            (df_cumulative_balance['TO_CATEGORY'] == to_cat) & \n",
    "            (df_cumulative_balance['IMB_FAC_CATEGORY'] == imb_fac_cat)\n",
    "        ].shape[0]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Define the color scheme for each quadrant\n",
    "color_scheme = {\n",
    "    ('too_many', 'under-utilized'): 'lightblue',\n",
    "    ('too_many', 'well-utilized'): 'blue',\n",
    "    ('too_many', 'highly-utilized'): 'darkblue',\n",
    "    ('balanced', 'under-utilized'): 'lightgreen',\n",
    "    ('balanced', 'well-utilized'): 'green',\n",
    "    ('balanced', 'highly-utilized'): 'darkgreen',\n",
    "    ('too_few', 'under-utilized'): 'lightcoral',\n",
    "    ('too_few', 'well-utilized'): 'red',\n",
    "    ('too_few', 'highly-utilized'): 'darkred'\n",
    "}\n",
    "\n",
    "# Create a scatter plot with circle sizes based on the counts and fixed color scheme\n",
    "for i, imb_fac_cat in enumerate(imb_fac_categories):\n",
    "    for j, to_cat in enumerate(to_categories):\n",
    "        count = counts.loc[imb_fac_cat, to_cat]\n",
    "        color = color_scheme.get((imb_fac_cat, to_cat), 'white')  # Use 'white' for no values\n",
    "        ax.scatter(j, i, s=count*10*2.0, alpha=0.6, edgecolors='w', color=color)  # Increase size by 25%\n",
    "        ax.text(j, i, count, ha='center', va='center', color='black')\n",
    "\n",
    "# Set the x and y axis labels\n",
    "ax.set_xticks(range(len(to_categories)))\n",
    "ax.set_xticklabels(to_categories)\n",
    "ax.set_yticks(range(len(imb_fac_categories)))\n",
    "ax.set_yticklabels(imb_fac_categories)\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xlabel('Turnover')\n",
    "ax.set_ylabel('Imbalance')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Station categorization\\n based on Turnover & Imbalance')\n",
    "\n",
    "# Adjust the x and y limits to add padding\n",
    "ax.set_xlim(-0.5, len(to_categories) - 0.5)\n",
    "ax.set_ylim(-0.5, len(imb_fac_categories) - 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Create a base map\n",
    "m = folium.Map(location=[df_cumulative_balance['LAT'].mean(), df_cumulative_balance['LNG'].mean()], zoom_start=12)\n",
    "\n",
    "# Function to determine color based on TO_IMB_CATEGORY\n",
    "def get_color(to_imb_category):\n",
    "    return color_scheme.get(to_imb_category, 'blue')\n",
    "\n",
    "# Function to update the map for a specific week\n",
    "def update_map(week_nr):\n",
    "    # Clear all markers from the map\n",
    "    m = folium.Map(location=[df_cumulative_balance['LAT'].mean(), df_cumulative_balance['LNG'].mean()], zoom_start=12) # Use zoom = 13 if you want to see the stations in more detail\n",
    "    \n",
    "    \n",
    "    # Add stations to the map for the given week\n",
    "    week_data = df_cumulative_balance[df_cumulative_balance['WEEK_NR'] == week_nr]\n",
    "    for _, row in week_data.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['LAT'], row['LNG']],\n",
    "            radius=5 + abs(row['IMBALANCE_FACTOR']) * 5,  # Scale the size based on IMBALANCE_FACTOR\n",
    "            color=get_color((row['IMB_FAC_CATEGORY'], row['TO_CATEGORY'])),\n",
    "            fill=True,\n",
    "            fill_color=get_color((row['IMB_FAC_CATEGORY'], row['TO_CATEGORY'])),\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Station: {row['STATION']}\\nTurnover: {row['TURNOVER']:.2f}\\nImbalance Factor: {row['IMBALANCE_FACTOR']:.2f}\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Add a progress display\n",
    "    progress_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 10px; left: 50%; transform: translateX(-50%); \n",
    "                width: 200px; height: 30px; \n",
    "                border:2px solid grey; z-index:9999; font-size:16px;\n",
    "                background-color:white; opacity: 0.8;\n",
    "                text-align: center; line-height: 30px;\">\n",
    "    Week {week_nr} / 52\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(progress_html))\n",
    "    \n",
    "    return m\n",
    "    # Add a legend to the map\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 250px; height: 150px; \n",
    "                border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                background-color:white; opacity: 0.8;\n",
    "                padding: 10px;\">\n",
    "    <b>Legend</b><br>\n",
    "    <i style=\"background:lightcoral; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Too Few &nbsp;&nbsp;<br>\n",
    "    <i style=\"background:lightgreen; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Balanced &nbsp;&nbsp;<br>\n",
    "    <i style=\"background:lightblue; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Too Many &nbsp;&nbsp;<br>\n",
    "    <i style=\"background:darkred; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Highly Utilized &nbsp;&nbsp;<br>\n",
    "    <i style=\"background:darkgreen; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Well Utilized &nbsp;&nbsp;<br>\n",
    "    <i style=\"background:blue; width: 10px; height: 10px; display: inline-block; border-radius: 50%;\"></i> Under Utilized &nbsp;&nbsp;\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "# Loop through each week and update the map\n",
    "for week in range(1, 53):\n",
    "    m = update_map(week)\n",
    "    clear_output(wait=True)\n",
    "    display(m)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEGEND IS MISSING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "m1 = folium.Map(location=[df_cumulative_balance['LAT'].mean(), df_cumulative_balance['LNG'].mean()], zoom_start=12)\n",
    "\n",
    "# Function to determine color based on turnover category\n",
    "def get_color(turnover_category):\n",
    "    category_colors = {\n",
    "        'highly-utilized': 'darkred',\n",
    "        'healthy': 'green',\n",
    "        'medium': 'lightgreen',\n",
    "        'under-utiltized': 'lightgrey',\n",
    "        'excess-capacity': 'grey'\n",
    "    }\n",
    "    return category_colors.get(turnover_category, 'blue')\n",
    "\n",
    "# Add stations to the map\n",
    "for _, row in df_cumulative_balance.iterrows():\n",
    "    # Scale the turnover values to a range between 1 and 20\n",
    "    scaled_turnover = 1 + (row['TURNOVER'] - df_cumulative_balance['TURNOVER'].min()) * (20 - 1) / (df_cumulative_balance['TURNOVER'].max() - df_cumulative_balance['TURNOVER'].min())\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['LAT'], row['LNG']],\n",
    "        radius=scaled_turnover,  # Use the scaled turnover for the radius\n",
    "        color=get_color(row['TO_CATEGORY']),\n",
    "        fill=True,\n",
    "        fill_color=get_color(row['TO_CATEGORY']),\n",
    "        fill_opacity=0.6,\n",
    "        popup=f\"Station: {row['STATION']}\\nTurnover: {row['TURNOVER']:.2f}\\nCategory: {row['TO_CATEGORY']}\"\n",
    "    ).add_to(m1)\n",
    "\n",
    "# Create a legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 150px; height: 150px; \n",
    "            border:2px solid grey; z-index:9999; font-size:14px;\n",
    "            background-color:white; opacity: 0.8;\n",
    "            \">\n",
    "&emsp;<b>Legend</b><br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:darkred\"></i>&emsp;Highly-utilized<br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:green\"></i>&emsp;Healthy<br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:lightgreen\"></i>&emsp;Medium<br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:lightgrey\"></i>&emsp;Under-utilized<br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:grey\"></i>&emsp;Excess-capacity\n",
    "</div>\n",
    "'''\n",
    "\n",
    "m1.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Display the map\n",
    "m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Define the latitude and longitude coordinates of Washington DC\n",
    "dc_coordinates = (38.907192, -77.046873)  # Adjusted Longitude by 1km to the south\n",
    "\n",
    "# Function to calculate distance in kilometers\n",
    "def calculate_distance(lat, lng):\n",
    "    station_coordinates = (lat, lng)\n",
    "    return geodesic(dc_coordinates, station_coordinates).kilometers\n",
    "\n",
    "# Calculate the distance for each station and assign the new columns\n",
    "df_cumulative_balance['distance_to_centre_km'] = df_cumulative_balance.apply(\n",
    "    lambda row: round(calculate_distance(row['LAT'], row['LNG']), 1), axis=1\n",
    ")\n",
    "\n",
    "# Assign 'inside_outside' based on the distance\n",
    "df_cumulative_balance['inside_outside'] = df_cumulative_balance['distance_to_centre_km'].apply(\n",
    "    lambda x: 'in_centre' if x <= 11 else 'outside_centre'\n",
    ")\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Create a pie chart for 'inside_outside' category\n",
    "plt.figure(figsize=(8, 8))\n",
    "df_cumulative_balance['inside_outside'].value_counts().plot(\n",
    "    kind='pie', \n",
    "    autopct='%1.1f%%', \n",
    "    startangle=140, \n",
    "    colors=['green', 'red'], \n",
    "    labels=['In Centre', 'Outside Centre']\n",
    ")\n",
    "\n",
    "# Set the title\n",
    "plt.title('Distribution of Stations by Location (Inside/Outside Centre)')\n",
    "plt.ylabel('')  # Remove the y-axis label for better visualization\n",
    "\n",
    "# Add a legend with the actual total count for each category\n",
    "counts = df_cumulative_balance['inside_outside'].value_counts()\n",
    "legend_labels = [f\"In Centre: {counts['in_centre']}\", f\"Outside Centre: {counts['outside_centre']}\"]\n",
    "plt.legend(legend_labels, loc='upper left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map centered around Washington DC\n",
    "m = folium.Map(location=[38.907192, -77.036873], zoom_start=12)\n",
    "\n",
    "# Add a circle of 15km radius around the center of Washington DC\n",
    "folium.Circle(\n",
    "    location=[38.907192, -77.046873], # adjusted coordinate 1km to south\n",
    "    radius=11000,\n",
    "    color='blue',\n",
    "    fill=True,\n",
    "    fill_opacity=0.1,\n",
    "    popup='11km Radius'\n",
    ").add_to(m)\n",
    "\n",
    "# Function to determine color based on 'inside_outside' column\n",
    "def get_color(inside_outside):\n",
    "    return 'green' if inside_outside == 'in_centre' else 'red'\n",
    "\n",
    "# Add stations to the map\n",
    "for _, row in df_cumulative_balance.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LAT'], row['LNG']],\n",
    "        radius=5,\n",
    "        color=get_color(row['inside_outside']),\n",
    "        fill=True,\n",
    "        fill_color=get_color(row['inside_outside']),\n",
    "        fill_opacity=0.6,\n",
    "        popup=f\"Station: {row['STATION']}\\nDistance to Center: {row['distance_to_centre_km']} km\\nCategory: {row['inside_outside']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add a legend to the map\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 200px; height: 90px; \n",
    "            border:2px solid grey; z-index:9999; font-size:14px;\n",
    "            background-color:white; opacity: 0.8;\n",
    "            \">\n",
    "&emsp;<b>Legend</b><br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:green\"></i>&emsp;In Centre<br>\n",
    "&emsp;<i class=\"fa fa-circle\" style=\"color:red\"></i>&emsp;Outside Centre\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of reading a CSV file\n",
    "df_offices = pd.read_csv('offices.csv')\n",
    "df_offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the 'office_score' column in df_cumulative_balance with 0\n",
    "df_cumulative_balance['office_score'] = 0.0\n",
    "\n",
    "# Iterate over each station in df_cumulative_balance\n",
    "for station_index, station_row in df_cumulative_balance.iterrows():\n",
    "    station_coords = (station_row['LAT'], station_row['LNG'])\n",
    "    office_score = 0.0\n",
    "    \n",
    "    # Iterate over each office in df_offices\n",
    "    for office_index, office_row in df_offices.iterrows():\n",
    "        office_coords = (office_row['Latitude'], office_row['Longitude'])\n",
    "        \n",
    "        # Calculate the distance between the station and the office\n",
    "        distance = geodesic(station_coords, office_coords).meters\n",
    "        \n",
    "        # If the distance is less than 500 meters, add the office factor to the office_score\n",
    "        if distance < 500:\n",
    "            office_score += office_row['Office_Factor']\n",
    "    \n",
    "    # Update the 'office_score' column for the station\n",
    "    df_cumulative_balance.at[station_index, 'office_score'] = office_score\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by 'office_score' in descending order and select the top 20 stations\n",
    "top_20_stations_by_office_score = df_cumulative_balance.sort_values(by='office_score', ascending=False).head(20)\n",
    "\n",
    "# Display the result\n",
    "top_20_stations_by_office_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import CustomIcon\n",
    "\n",
    "# Add office locations to the map with custom building icons\n",
    "for _, office_row in df_offices.iterrows():\n",
    "    icon = CustomIcon(\n",
    "        icon_image='building2.png',  # Path to the building image\n",
    "        icon_size=(30, 30)  # Adjust the size of the icon\n",
    "    )\n",
    "    folium.Marker(\n",
    "        location=[office_row['Latitude'], office_row['Longitude']],\n",
    "        icon=icon,\n",
    "        popup=f\"Office: {office_row['Office_Location_Name']}<br>\"\n",
    "              f\"Category: {office_row['Category']}<br>\"\n",
    "              f\"Industry: {office_row['Industry Sector']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the updated map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading a CSV file\n",
    "df_metrorail_all = pd.read_csv('Metro_Stations_Regional.csv', sep=',')\n",
    "df_metrorail_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "\n",
    "# Define the projection for the X, Y coordinates (assuming they are in EPSG:3857 - Web Mercator)\n",
    "# Replace 'EPSG:3857' with the correct projection if different\n",
    "proj_from = Proj(init='epsg:3857')  # Source projection\n",
    "proj_to = Proj(init='epsg:4326')    # Target projection (WGS84 - Latitude/Longitude)\n",
    "\n",
    "# Function to transform X, Y coordinates to latitude and longitude\n",
    "def transform_coordinates(x, y):\n",
    "    try:\n",
    "        lon, lat = transform(proj_from, proj_to, x, y)\n",
    "        return lat, lon\n",
    "    except Exception as e:\n",
    "        print(f\"Error transforming coordinates ({x}, {y}): {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Ensure the columns 'X' and 'Y' exist in df_metrorail_all\n",
    "if 'X' in df_metrorail_all.columns and 'Y' in df_metrorail_all.columns:\n",
    "    # Add latitude and longitude columns to df_metrorail_all\n",
    "    df_metrorail_all[['Latitude', 'Longitude']] = df_metrorail_all.apply(\n",
    "        lambda row: pd.Series(transform_coordinates(row['X'], row['Y'])), axis=1\n",
    "    )\n",
    "else:\n",
    "    print(\"Error: The columns 'X' and 'Y' do not exist in df_metrorail_all. Please check the DataFrame.\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_metrorail_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the 'count_metrorail_st_walking_dist' column in df_cumulative_balance with 0\n",
    "df_cumulative_balance['count_metrorail_st_walking_dist'] = 0\n",
    "\n",
    "# Iterate over each station in df_cumulative_balance\n",
    "for station_index, station_row in df_cumulative_balance.iterrows():\n",
    "    station_coords = (station_row['LAT'], station_row['LNG'])\n",
    "    count_metrorail_stations = 0\n",
    "    \n",
    "    # Iterate over each station in df_metrorail_all\n",
    "    for _, metro_row in df_metrorail_all.iterrows():\n",
    "        metro_coords = (metro_row['Latitude'], metro_row['Longitude'])\n",
    "        \n",
    "        # Calculate the distance between the station and the metro station\n",
    "        distance = geodesic(station_coords, metro_coords).meters\n",
    "        \n",
    "        # If the distance is less than 500 meters, increment the count\n",
    "        if distance < 500:\n",
    "            count_metrorail_stations += 1\n",
    "    \n",
    "    # Update the 'count_metrorail_st_walking_dist' column for the station\n",
    "    df_cumulative_balance.at[station_index, 'count_metrorail_st_walking_dist'] = count_metrorail_stations\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a group count for 'count_metrorail_st_walking_dist'\n",
    "group_count = df_cumulative_balance['count_metrorail_st_walking_dist'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(group_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import CustomIcon\n",
    "\n",
    "# Add Metrorail stations to the map with custom metro icons\n",
    "for _, metro_row in df_metrorail_all.iterrows():\n",
    "    icon = CustomIcon(\n",
    "        icon_image='metro_icon.png',  # Path to the metro icon image\n",
    "        icon_size=(30, 30)  # Adjust the size of the icon\n",
    "    )\n",
    "    folium.Marker(\n",
    "        location=[metro_row['Latitude'], metro_row['Longitude']],\n",
    "        icon=icon,\n",
    "        popup=f\"Metrorail Station: {metro_row['NAME']}<br>\"\n",
    "            \n",
    "              \n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the updated map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of reading a CSV file\n",
    "df_leisure = pd.read_csv('leisure.csv')\n",
    "df_leisure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the 'leisure_score' column in df_cumulative_balance with 0\n",
    "df_cumulative_balance['leisure_score'] = 0.0\n",
    "\n",
    "# Iterate over each station in df_cumulative_balance\n",
    "for station_index, station_row in df_cumulative_balance.iterrows():\n",
    "    station_coords = (station_row['LAT'], station_row['LNG'])\n",
    "    leisure_score = 0.0\n",
    "    \n",
    "    # Iterate over each leisure location in df_leisure\n",
    "    for leisure_index, leisure_row in df_leisure.iterrows():\n",
    "        leisure_coords = (leisure_row['Latitude'], leisure_row['Longitude'])\n",
    "        \n",
    "        # Calculate the distance between the station and the leisure location\n",
    "        distance = geodesic(station_coords, leisure_coords).meters\n",
    "        \n",
    "        # If the distance is less than 500 meters, add the leisure factor to the leisure_score\n",
    "        if distance < 500:\n",
    "            leisure_score += leisure_row['leisure_factor']\n",
    "    \n",
    "    # Update the 'leisure_score' column for the station\n",
    "    df_cumulative_balance.at[station_index, 'leisure_score'] = leisure_score\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import CustomIcon\n",
    "\n",
    "# Add leisure locations to the map with custom leisure icons\n",
    "for _, leisure_row in df_leisure.iterrows():\n",
    "    icon = CustomIcon(\n",
    "        icon_image='leisure.png',  # Path to the leisure icon image\n",
    "        icon_size=(30, 30)  # Adjust the size of the icon\n",
    "    )\n",
    "    folium.Marker(\n",
    "        location=[leisure_row['Latitude'], leisure_row['Longitude']],\n",
    "        icon=icon,\n",
    "        popup=f\"Leisure Location: {leisure_row['Leisure_Location']}<br>\"\n",
    "              f\"Annual Visitors: {leisure_row['Annual_Visitors']}<br>\"\n",
    "              f\"Ranking: {leisure_row['Ranking']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the updated map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of reading a CSV file\n",
    "df_residential = pd.read_csv('residential.csv')\n",
    "df_residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the 'residential_count' column in df_cumulative_balance with 0\n",
    "df_cumulative_balance['residential_count'] = 0\n",
    "\n",
    "# Iterate over each station in df_cumulative_balance\n",
    "for station_index, station_row in df_cumulative_balance.iterrows():\n",
    "    station_coords = (station_row['LAT'], station_row['LNG'])\n",
    "    residential_count = 0\n",
    "    \n",
    "    # Iterate over each residential location in df_residential\n",
    "    for residential_index, residential_row in df_residential.iterrows():\n",
    "        residential_coords = (residential_row['Latitude'], residential_row['Longitude'])\n",
    "        \n",
    "        # Calculate the distance between the station and the residential location\n",
    "        distance = geodesic(station_coords, residential_coords).meters\n",
    "        \n",
    "        # If the distance is less than 500 meters, increment the residential_count\n",
    "        if distance < 500:\n",
    "            residential_count += 1\n",
    "    \n",
    "    # Update the 'residential_count' column for the station\n",
    "    df_cumulative_balance.at[station_index, 'residential_count'] = residential_count\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a group count for 'residential_count'\n",
    "group_count = df_cumulative_balance['residential_count'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(group_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import CustomIcon\n",
    "\n",
    "# Add residential locations to the map with custom residential icons\n",
    "for _, residential_row in df_residential.iterrows():\n",
    "    icon = CustomIcon(\n",
    "        icon_image='residential.png',  # Path to the residential icon image\n",
    "        icon_size=(30, 30)  # Adjust the size of the icon\n",
    "    )\n",
    "    folium.Marker(\n",
    "        location=[residential_row['Latitude'], residential_row['Longitude']],\n",
    "        icon=icon,\n",
    "        popup=f\"Area: {residential_row['Area_Name']}<br>\"\n",
    "              f\"Population Estimate 2023: {residential_row['Population_Estimate_2023']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the updated map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of reading a CSV file\n",
    "df_venues = pd.read_csv('venues.csv')\n",
    "df_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the 'venue_count' column in df_cumulative_balance with 0\n",
    "df_cumulative_balance['venue_count'] = 0\n",
    "\n",
    "# Iterate over each station in df_cumulative_balance\n",
    "for station_index, station_row in df_cumulative_balance.iterrows():\n",
    "    station_coords = (station_row['LAT'], station_row['LNG'])\n",
    "    venue_count = 0\n",
    "    \n",
    "    # Iterate over each venue in df_venues\n",
    "    for venue_index, venue_row in df_venues.iterrows():\n",
    "        venue_coords = (venue_row['Latitude'], venue_row['Longitude'])\n",
    "        \n",
    "        # Calculate the distance between the station and the venue\n",
    "        distance = geodesic(station_coords, venue_coords).meters\n",
    "        \n",
    "        # If the distance is less than 500 meters, increment the venue_count\n",
    "        if distance < 500:\n",
    "            venue_count += 1\n",
    "    \n",
    "    # Update the 'venue_count' column for the station\n",
    "    df_cumulative_balance.at[station_index, 'venue_count'] = venue_count\n",
    "\n",
    "df_cumulative_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a group count for 'venue_count'\n",
    "group_count = df_cumulative_balance['venue_count'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(group_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import CustomIcon\n",
    "\n",
    "# Add venue locations to the map with custom venue icons\n",
    "for _, venue_row in df_venues.iterrows():\n",
    "    icon = CustomIcon(\n",
    "        icon_image='venues.png',  # Path to the venue icon image\n",
    "        icon_size=(30, 30)  # Adjust the size of the icon\n",
    "    )\n",
    "    folium.Marker(\n",
    "        location=[venue_row['Latitude'], venue_row['Longitude']],\n",
    "        icon=icon,\n",
    "        popup=f\"Venue: {venue_row['Venue_Name']}<br>\"\n",
    "              f\"Category: {venue_row['Venue_Category']}<br>\"\n",
    "              f\"Annual Customer Visits: {venue_row['Annual_Customer_Visits']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the updated map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Define the hue variable and its unique values\n",
    "hue_var = \"inside_outside\"\n",
    "hue_values = df_cumulative_balance[hue_var].unique()\n",
    "colors = sns.color_palette(\"tab10\", len(hue_values))\n",
    "\n",
    "# Plot 1: Correlation between apparent temperature and total rides\n",
    "for hue_value, color in zip(hue_values, colors):\n",
    "\tsubset = df_cumulative_balance[df_cumulative_balance[hue_var] == hue_value]\n",
    "\tsns.regplot(data=subset, x=\"COUNT_PICKUP\", y=\"distance_to_centre_km\", ax=axs[0], scatter_kws={'color': color}, line_kws={'color': color}, label=hue_value)\n",
    "axs[0].set_title(\"Number of pick-ups vs Station distance to city centre\")\n",
    "axs[0].legend(title=hue_var)\n",
    "\n",
    "# Plot 2: Correlation between temperature and member rides\n",
    "for hue_value, color in zip(hue_values, colors):\n",
    "\tsubset = df_cumulative_balance[df_cumulative_balance[hue_var] == hue_value]\n",
    "\tsns.regplot(data=subset, x=\"TURNOVER\", y=\"distance_to_centre_km\", ax=axs[1], scatter_kws={'color': color}, line_kws={'color': color}, label=hue_value)\n",
    "axs[1].set_title(\"Turnover vs Station distance to city centre\")\n",
    "axs[1].legend(title=hue_var)\n",
    "\n",
    "# Plot 3: Correlation between windspeed and casual rides\n",
    "for hue_value, color in zip(hue_values, colors):\n",
    "\tsubset = df_cumulative_balance[df_cumulative_balance[hue_var] == hue_value]\n",
    "\tsns.regplot(data=subset, x=\"IMBALANCE_FACTOR\", y=\"distance_to_centre_km\", ax=axs[2], scatter_kws={'color': color}, line_kws={'color': color}, label=hue_value)\n",
    "axs[2].set_title(\"Imbalance Factor vs Station distance to city centre\")\n",
    "axs[2].legend(title=hue_var)\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Correlation between station distance to city centre and number of pick-ups\n",
    "sns.regplot(data=df_cumulative_balance, x=\"COUNT_PICKUP\", y=\"distance_to_centre_km\", ax=axs[0], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0].set_title(\"Number of pick-ups vs Station distance to city centre\")\n",
    "\n",
    "# Plot 2: Correlation between turnover and station distance to city centre\n",
    "sns.regplot(data=df_cumulative_balance, x=\"TURNOVER\", y=\"distance_to_centre_km\", ax=axs[1], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1].set_title(\"Turnover vs Station distance to city centre\")\n",
    "\n",
    "# Plot 3: Correlation between imbalance factor and station distance to city centre\n",
    "sns.regplot(data=df_cumulative_balance, x=\"IMBALANCE_FACTOR\", y=\"distance_to_centre_km\", ax=axs[2], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[2].set_title(\"Imbalance Factor vs Station distance to city centre\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Correlation between office score and turnover\n",
    "sns.regplot(data=df_cumulative_balance, x=\"office_score\", y=\"TURNOVER\", ax=axs[0], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0].set_title(\"Turnover vs Office Score\")\n",
    "axs[0].set_xlabel(\"Office Score\")\n",
    "axs[0].set_ylabel(\"Turnover\")\n",
    "\n",
    "# Plot 2: Correlation between count of metrorail stations within walking distance and turnover\n",
    "sns.regplot(data=df_cumulative_balance, x=\"count_metrorail_st_walking_dist\", y=\"TURNOVER\", ax=axs[1], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1].set_title(\"Turnover vs Count of Metrorail Stations (Walking Distance)\")\n",
    "axs[1].set_xlabel(\"Count of Metrorail Stations\")\n",
    "axs[1].set_ylabel(\"Turnover\")\n",
    "\n",
    "# Plot 3: Correlation between leisure score and turnover\n",
    "sns.regplot(data=df_cumulative_balance, x=\"leisure_score\", y=\"TURNOVER\", ax=axs[2], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[2].set_title(\"Turnover vs Leisure Score\")\n",
    "axs[2].set_xlabel(\"Leisure Score\")\n",
    "axs[2].set_ylabel(\"Turnover\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Correlation between office score and imbalance factor\n",
    "sns.regplot(data=df_cumulative_balance, x=\"office_score\", y=\"IMBALANCE_FACTOR\", ax=axs[0], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0].set_title(\"Imbalance Factor vs Office Score\")\n",
    "axs[0].set_xlabel(\"Office Score\")\n",
    "axs[0].set_ylabel(\"Imbalance Factor\")\n",
    "\n",
    "# Plot 2: Correlation between count of metrorail stations within walking distance and imbalance factor\n",
    "sns.regplot(data=df_cumulative_balance, x=\"count_metrorail_st_walking_dist\", y=\"IMBALANCE_FACTOR\", ax=axs[1], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1].set_title(\"Imbalance Factor vs Count of Metrorail Stations (Walking Distance)\")\n",
    "axs[1].set_xlabel(\"Count of Metrorail Stations\")\n",
    "axs[1].set_ylabel(\"Imbalance Factor\")\n",
    "\n",
    "# Plot 3: Correlation between leisure score and imbalance factor\n",
    "sns.regplot(data=df_cumulative_balance, x=\"leisure_score\", y=\"IMBALANCE_FACTOR\", ax=axs[2], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[2].set_title(\"Imbalance Factor vs Leisure Score\")\n",
    "axs[2].set_xlabel(\"Leisure Score\")\n",
    "axs[2].set_ylabel(\"Imbalance Factor\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x4 grid of subplots\n",
    "fig, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "# First row\n",
    "# Plot 1: Correlation between residential count and number of pick-ups\n",
    "sns.regplot(data=df_cumulative_balance, x=\"residential_count\", y=\"COUNT_PICKUP\", ax=axs[0, 0], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0, 0].set_title(\"Residential Count vs Number of Pick-ups\")\n",
    "axs[0, 0].set_xlabel(\"Residential Count\")\n",
    "axs[0, 0].set_ylabel(\"Number of Pick-ups\")\n",
    "\n",
    "# Plot 2: Correlation between residential count and number of returns\n",
    "sns.regplot(data=df_cumulative_balance, x=\"residential_count\", y=\"COUNT_RETURN\", ax=axs[0, 1], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0, 1].set_title(\"Residential Count vs Number of Returns\")\n",
    "axs[0, 1].set_xlabel(\"Residential Count\")\n",
    "axs[0, 1].set_ylabel(\"Number of Returns\")\n",
    "\n",
    "# Plot 3: Correlation between residential count and turnover\n",
    "sns.regplot(data=df_cumulative_balance, x=\"residential_count\", y=\"TURNOVER\", ax=axs[0, 2], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0, 2].set_title(\"Residential Count vs Turnover\")\n",
    "axs[0, 2].set_xlabel(\"Residential Count\")\n",
    "axs[0, 2].set_ylabel(\"Turnover\")\n",
    "\n",
    "# Plot 4: Correlation between residential count and imbalance factor\n",
    "sns.regplot(data=df_cumulative_balance, x=\"residential_count\", y=\"IMBALANCE_FACTOR\", ax=axs[0, 3], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[0, 3].set_title(\"Residential Count vs Imbalance Factor\")\n",
    "axs[0, 3].set_xlabel(\"Residential Count\")\n",
    "axs[0, 3].set_ylabel(\"Imbalance Factor\")\n",
    "\n",
    "# Second row\n",
    "# Plot 1: Correlation between venues count and number of pick-ups\n",
    "sns.regplot(data=df_cumulative_balance, x=\"venue_count\", y=\"COUNT_PICKUP\", ax=axs[1, 0], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1, 0].set_title(\"Venues Count vs Number of Pick-ups\")\n",
    "axs[1, 0].set_xlabel(\"Venues Count\")\n",
    "axs[1, 0].set_ylabel(\"Number of Pick-ups\")\n",
    "\n",
    "# Plot 2: Correlation between venues count and number of returns\n",
    "sns.regplot(data=df_cumulative_balance, x=\"venue_count\", y=\"COUNT_RETURN\", ax=axs[1, 1], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1, 1].set_title(\"Venues Count vs Number of Returns\")\n",
    "axs[1, 1].set_xlabel(\"Venues Count\")\n",
    "axs[1, 1].set_ylabel(\"Number of Returns\")\n",
    "\n",
    "# Plot 3: Correlation between venues count and turnover\n",
    "sns.regplot(data=df_cumulative_balance, x=\"venue_count\", y=\"TURNOVER\", ax=axs[1, 2], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1, 2].set_title(\"Venues Count vs Turnover\")\n",
    "axs[1, 2].set_xlabel(\"Venues Count\")\n",
    "axs[1, 2].set_ylabel(\"Turnover\")\n",
    "\n",
    "# Plot 4: Correlation between venues count and imbalance factor\n",
    "sns.regplot(data=df_cumulative_balance, x=\"venue_count\", y=\"IMBALANCE_FACTOR\", ax=axs[1, 3], scatter_kws={'color': 'blue'}, line_kws={'color': 'blue'})\n",
    "axs[1, 3].set_title(\"Venues Count vs Imbalance Factor\")\n",
    "axs[1, 3].set_xlabel(\"Venues Count\")\n",
    "axs[1, 3].set_ylabel(\"Imbalance Factor\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_balance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_numeric = df_cumulative_balance.select_dtypes(include=['float64', 'int64']).dropna().copy()\n",
    "df_cumulative_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumulative_numeric.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows where TURNOVER is greater than 5\n",
    "count_above_5 = df_cumulative_balance[df_cumulative_balance['TURNOVER'] > 7].shape[0]\n",
    "print(\"Number of rows with TURNOVER above 7:\", count_above_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 1 row and 4 columns for the box plots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 6))\n",
    "\n",
    "# Boxplot for 'COUNT_PICKUP'\n",
    "sns.boxplot(data=df_cumulative_balance, y='COUNT_PICKUP', ax=axs[0])\n",
    "axs[0].set_title('Boxplot of Count Pickup')\n",
    "axs[0].set_ylabel('COUNT_PICKUP')\n",
    "\n",
    "# Boxplot for 'COUNT_RETURN'\n",
    "sns.boxplot(data=df_cumulative_balance, y='COUNT_RETURN', ax=axs[1])\n",
    "axs[1].set_title('Boxplot of Count Return')\n",
    "axs[1].set_ylabel('COUNT_RETURN')\n",
    "\n",
    "# Boxplot for 'TURNOVER'\n",
    "sns.boxplot(data=df_cumulative_balance, y='TURNOVER', ax=axs[2])\n",
    "axs[2].set_title('Boxplot of Turnover')\n",
    "axs[2].set_ylabel('TURNOVER')\n",
    "\n",
    "# Boxplot for 'IMBALANCE_FACTOR'\n",
    "sns.boxplot(data=df_cumulative_balance, y='IMBALANCE_FACTOR', ax=axs[3])\n",
    "axs[3].set_title('Boxplot of Imbalance Factor')\n",
    "axs[3].set_ylabel('IMBALANCE_FACTOR')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df_cumulative_balance['TURNOVER'].quantile(0.25)\n",
    "Q3 = df_cumulative_balance['TURNOVER'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_cumulative_balance[df_cumulative_balance['TURNOVER'] > upper_bound]\n",
    "\n",
    "# Display the outliers\n",
    "print(\"Outliers in 'TURNOVER':\")\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate outliers for a given column\n",
    "def calculate_outliers(column_name):\n",
    "    Q1 = df_cumulative_balance[column_name].quantile(0.25)\n",
    "    Q3 = df_cumulative_balance[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df_cumulative_balance[(df_cumulative_balance[column_name] < lower_bound) | \n",
    "                                 (df_cumulative_balance[column_name] > upper_bound)]\n",
    "\n",
    "# Calculate outliers for each column\n",
    "outliers_count_pickup = calculate_outliers('COUNT_PICKUP')\n",
    "outliers_count_return = calculate_outliers('COUNT_RETURN')\n",
    "outliers_turnover = calculate_outliers('TURNOVER')\n",
    "outliers_imbalance_factor = calculate_outliers('IMBALANCE_FACTOR')\n",
    "\n",
    "# Combine the results into a single dataframe to compare\n",
    "df_cumulative_balance['is_outlier_count_pickup'] = df_cumulative_balance['STATION'].isin(outliers_count_pickup['STATION'])\n",
    "df_cumulative_balance['is_outlier_count_return'] = df_cumulative_balance['STATION'].isin(outliers_count_return['STATION'])\n",
    "df_cumulative_balance['is_outlier_turnover'] = df_cumulative_balance['STATION'].isin(outliers_turnover['STATION'])\n",
    "df_cumulative_balance['is_outlier_imbalance_factor'] = df_cumulative_balance['STATION'].isin(outliers_imbalance_factor['STATION'])\n",
    "\n",
    "# Count the number of criteria for which each station is an outlier\n",
    "df_cumulative_balance['outlier_criteria_count'] = (\n",
    "    df_cumulative_balance[['is_outlier_count_pickup', \n",
    "                            'is_outlier_count_return', \n",
    "                            'is_outlier_turnover', \n",
    "                            'is_outlier_imbalance_factor']].sum(axis=1)\n",
    ")\n",
    "\n",
    "# Count the number of stations that are outliers for 1, 2, 3, or 4 criteria\n",
    "outlier_counts = df_cumulative_balance['outlier_criteria_count'].value_counts().sort_index()\n",
    "outlier_counts\n",
    "\n",
    "# Visualize the results with a legend for outlier reasons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define colors for each outlier reason\n",
    "outlier_colors = {\n",
    "    'is_outlier_count_pickup': 'blue',\n",
    "    'is_outlier_count_return': 'orange',\n",
    "    'is_outlier_turnover': 'green',\n",
    "    'is_outlier_imbalance_factor': 'red'\n",
    "}\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Initialize a dictionary to store counts for each number of criteria and reason\n",
    "criteria_counts = {reason: [] for reason in outlier_colors.keys()}\n",
    "\n",
    "# Calculate counts for each number of criteria (1, 2, 3, 4) for each reason\n",
    "for num_criteria in range(1, 5):\n",
    "    for reason in outlier_colors.keys():\n",
    "        subset = df_cumulative_balance[\n",
    "            (df_cumulative_balance[reason]) & \n",
    "            (df_cumulative_balance['outlier_criteria_count'] == num_criteria)\n",
    "        ]\n",
    "        criteria_counts[reason].append(len(subset))\n",
    "\n",
    "# Define the bar width and x positions\n",
    "bar_width = 0.2\n",
    "x_positions = range(1, 5)\n",
    "\n",
    "# Plot bars for each outlier reason\n",
    "for i, (reason, counts) in enumerate(criteria_counts.items()):\n",
    "    plt.bar(\n",
    "        [x + i * bar_width for x in x_positions], \n",
    "        counts, \n",
    "        color=outlier_colors[reason], \n",
    "        width=bar_width, \n",
    "        label=reason.replace('is_outlier_', '').replace('_', ' ').title()\n",
    "    )\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Number of Stations Considered Outliers by Number of Criteria')\n",
    "plt.xlabel('Number of Criteria')\n",
    "plt.ylabel('Number of Stations')\n",
    "plt.xticks([x + 1.5 * bar_width for x in x_positions], x_positions)  # Center the x-ticks\n",
    "plt.legend(title='Outlier Reason')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df_cumulative_numeric.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups = df_cumulative_numeric[\"COUNT_PICKUP\"]\n",
    "imbalance = df_cumulative_numeric[\"IMBALANCE_FACTOR\"]\n",
    "turnover = df_cumulative_numeric[\"TURNOVER\"]\n",
    "distance = df_cumulative_numeric[\"distance_to_centre_km\"]\n",
    "office = df_cumulative_numeric[\"office_score\"]\n",
    "metro_count = df_cumulative_numeric[\"count_metrorail_st_walking_dist\"]\n",
    "leisure = df_cumulative_numeric[\"leisure_score\"]\n",
    "residential = df_cumulative_numeric[\"residential_count\"]\n",
    "venues = df_cumulative_numeric[\"venue_count\"]\n",
    "\n",
    "print(pickups.shape)\n",
    "print(imbalance.shape)\n",
    "print(turnover.shape)\n",
    "print(distance.shape)\n",
    "print(office.shape)\n",
    "print(metro_count.shape)\n",
    "print(leisure.shape)\n",
    "print(residential.shape)\n",
    "print(venues.shape)\n",
    "\n",
    "print(pickups.isnull().sum())\n",
    "print(imbalance.isnull().sum())\n",
    "print(turnover.isnull().sum())\n",
    "print(distance.isnull().sum())\n",
    "print(office.isnull().sum())\n",
    "print(metro_count.isnull().sum())\n",
    "print(leisure.isnull().sum())\n",
    "print(residential.isnull().sum())\n",
    "print(venues.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dfs to have value for the column instead of a null.\n",
    "\n",
    "pickups = pickups.values.reshape(-1, 1)\n",
    "imbalance = imbalance.values.reshape(-1, 1)\n",
    "turnover = turnover.values.reshape(-1, 1)\n",
    "distance = distance.values.reshape(-1, 1)\n",
    "metro_count = metro_count.values.reshape(-1, 1)\n",
    "leisure = leisure.values.reshape(-1, 1)\n",
    "residential = residential.values.reshape(-1, 1)\n",
    "venues = venues.values.reshape(-1, 1)\n",
    "\n",
    "print(pickups.shape)\n",
    "print(imbalance.shape)\n",
    "print(turnover.shape)\n",
    "print(distance.shape)\n",
    "print(metro_count.shape)\n",
    "print(leisure.shape)\n",
    "print(residential.shape)\n",
    "print(venues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups_train, pickups_test, distance_to_centre_train, distance_to_centre_test = train_test_split(pickups, distance_to_centre, test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_centre_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(distance_to_centre_train, pickups_train)\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(distance_to_centre_test)\n",
    "\n",
    "# Print the model coefficients and intercept\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2_score = model.score(distance_to_centre_test, pickups_test)\n",
    "print(\"R^2 Score:\", r2_score)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(pickups_test, predictions)\n",
    "mse = mean_squared_error(pickups_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) based on Distance to Centre is:\", mae)\n",
    "print(\"Mean Squared Error (MSE) based on Distance to Centre is:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) based on Distance to Centre is:\", rmse)\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_area_score = (model.score(distance_to_centre_test, pickups_test) * 100)\n",
    "print(\"The accuracy of the ML model based on Distance to Centre is:\", reg_area_score , \"%\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pickups_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(pickups_test, pickups_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Actual Pickups')\n",
    "plt.ylabel('Predicted Pickups')\n",
    "plt.title('Comparison of Test Data and Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(distance_to_centre_train, pickups_train.ravel())\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(distance_to_centre_test)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2_score = model.score(distance_to_centre_test, pickups_test)\n",
    "print(\"R^2 Score:\", r2_score)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(pickups_test, predictions)\n",
    "mse = mean_squared_error(pickups_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) based on Distance to Centre is:\", mae)\n",
    "print(\"Mean Squared Error (MSE) based on Distance to Centre is:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) based on Distance to Centre is:\", rmse)\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_area_score = (model.score(distance_to_centre_test, pickups_test) * 100)\n",
    "print(\"The accuracy of the ML model based on Distance to Centre is:\", reg_area_score , \"%\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pickups_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(pickups_test, pickups_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Actual Pickups')\n",
    "plt.ylabel('Predicted Pickups')\n",
    "plt.title('Comparison of Test Data and Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSIDE MODEL PERFROMS BETTER WHEN ASKED TO PREDICT distance_to_centre and using number of pickups as indicator\n",
    "See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(pickups_train, distance_to_centre_train.ravel())\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(pickups_test)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2_score = model.score(pickups_test, distance_to_centre_test)\n",
    "print(\"R^2 Score:\", r2_score)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(distance_to_centre_test, predictions)\n",
    "mse = mean_squared_error(distance_to_centre_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) based on Number of average daily pickups is:\", mae)\n",
    "print(\"Mean Squared Error (MSE) based on Number of average daily pickups is:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) based on Number of average daily pickups is:\", rmse)\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_area_score = (model.score(pickups_test, distance_to_centre_test) * 100)\n",
    "print(\"The accuracy of the ML model based on Number of average daily pickups is:\", reg_area_score , \"%\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(distance_to_centre_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(distance_to_centre_test, distance_to_centre_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Actual Distance to Centre')\n",
    "plt.ylabel('Predicted Distance to Centre')\n",
    "plt.title('Comparison of Test Data and Predictions (Model: Random Forest Regressor)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for training and testing\n",
    "turnover_train, turnover_test, distance_to_centre_train, distance_to_centre_test = train_test_split(turnover, distance_to_centre, test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_centre_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(distance_to_centre_train, turnover_train)\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(distance_to_centre_test)\n",
    "\n",
    "# Print the model coefficients and intercept\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2_score = model.score(distance_to_centre_test, turnover_test)\n",
    "print(\"R^2 Score:\", r2_score)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(turnover_test, predictions)\n",
    "mse = mean_squared_error(turnover_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) based on Distance to Centre is:\", mae)\n",
    "print(\"Mean Squared Error (MSE) based on Distance to Centre is:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) based on Distance to Centre is:\", rmse)\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_area_score = (model.score(distance_to_centre_test, turnover_test) * 100)\n",
    "print(\"The accuracy of the ML model based on Distance to Centre is:\", reg_area_score , \"%\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(distance_to_centre_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(distance_to_centre_test, turnover_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Distance to Centre')\n",
    "plt.ylabel('Turnover')\n",
    "plt.title('Comparison of Test Data and Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(distance_to_centre_train, turnover_train.ravel())\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(distance_to_centre_test)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2_score = model.score(distance_to_centre_test, turnover_test)\n",
    "print(\"R^2 Score:\", r2_score)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(turnover_test, predictions)\n",
    "mse = mean_squared_error(turnover_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) based on Distance to Centre is:\", mae)\n",
    "print(\"Mean Squared Error (MSE) based on Distance to Centre is:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) based on Distance to Centre is:\", rmse)\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_area_score = (model.score(distance_to_centre_test, turnover_test) * 100)\n",
    "print(\"The accuracy of the ML model based on Distance to Centre is:\", reg_area_score , \"%\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(distance_to_centre_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(distance_to_centre_test, turnover_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Distance to Centre')\n",
    "plt.ylabel('Turnover')\n",
    "plt.title('Comparison of Test Data and Predictions (Model: Random Forest Regressor)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTIVARIATE Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df_cumulative_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate = df_cumulative_numeric.drop(['TURNOVER', 'LAT', 'LNG', 'COUNT_PICKUP', 'COUNT_RETURN', 'CUMULATIVE_BALANCE', 'IMBALANCE_FACTOR'], axis='columns')\n",
    "turnover = df_cumulative_numeric['TURNOVER']\n",
    "\n",
    "print(multivariate.shape)\n",
    "print(turnover.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(turnover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "corr= multivariate.corr()\n",
    "matrix = np.triu(corr)\n",
    "sns.heatmap(corr, annot=True, mask=matrix, vmin=-1, vmax=1, cmap='seismic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dfs to have value for the column instead of a null.\n",
    "turnover = turnover.values.reshape(-1, 1)\n",
    "print(turnover.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test sets\n",
    "multivariate_01_train, multivariate_01_test, turnover_train, turnover_test = train_test_split(multivariate, turnover, test_size=0.2, random_state=420)\n",
    "\n",
    "# Train the model\n",
    "# Initialize and train the Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(\n",
    "    random_state=42, \n",
    "    n_estimators=48,  # Increase the number of trees\n",
    "    learning_rate=0.05,  # Lower learning rate for better generalization\n",
    "    max_depth=5,  # Increase depth for capturing complex patterns\n",
    "    min_samples_split=125,  # Minimum samples required to split an internal node\n",
    "    min_samples_leaf=10  # Minimum samples required to be at a leaf node\n",
    ")\n",
    "model.fit(multivariate_01_train, turnover_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predict values using test data.\n",
    "reg_multi_score = (model.score(multivariate_01_test, turnover_test) * 100).round(2)\n",
    "print(\"The accuracy of the ML model is:\", reg_multi_score , \"%\")\n",
    "\n",
    "# Predict the values for the test data\n",
    "predictions = model.predict(multivariate_01_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(turnover_test, predictions)\n",
    "mse = mean_squared_error(turnover_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(turnover_test, predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(turnover_test, predictions, color='blue', alpha=0.5, label='Predictions')\n",
    "plt.scatter(turnover_test, turnover_test, color='red', alpha=0.5, label='Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Actual Turnover')\n",
    "plt.ylabel('Predicted Turnover')\n",
    "plt.title('Comparison of Test Data and Predictions')\n",
    "plt.show()\n",
    "\n",
    "# Plot the fitted line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x=turnover_test.flatten(), y=predictions, scatter_kws={'color': 'blue', 'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "plt.xlabel('Actual Turnover')\n",
    "plt.ylabel('Predicted Turnover')\n",
    "plt.title('Fitted Line Plot: Actual vs Predicted Turnover')\n",
    "plt.show()\n",
    "\n",
    "# Ensure turnover_test and predictions have the same size\n",
    "if len(turnover_test) == len(predictions):\n",
    "\t# Calculate residuals\n",
    "\tresiduals = turnover_test - predictions\n",
    "\n",
    "\t# Plot Residuals versus Fits\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tplt.scatter(predictions, residuals, color='blue', alpha=0.5)\n",
    "\tplt.axhline(y=0, color='red', linestyle='--')\n",
    "\tplt.xlabel('Fitted Values (Predicted Turnover)')\n",
    "\tplt.ylabel('Residuals')\n",
    "\tplt.title('Residuals versus Fits')\n",
    "\tplt.show()\n",
    "else:\n",
    "\tprint(\"Error: turnover_test and predictions must have the same size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder for continuation\n",
    "\n",
    "1. Build cross-categories, i.e. TO_CATEGORY and IMBALANCE_BY_AVG_WEEK(OR BY SEASON)\n",
    "2. Change calculation method for balance to : # return - # pick-up\n",
    "3. balance categories \n",
    ">= 5 then 'too_many_returns'\n",
    ">1 & <5 then 'skewed_vs_returns'\n",
    ">=-1 & <=1 then 'balanced'\n",
    ">-5 & <-1 then 'skewed_vs_pick-ups'\n",
    "<=-5 then 'too_many_pick-ups'\n",
    "4. Considerations:\n",
    "\n",
    "5 subcategories each will create 25 new cross-categories for merge it might be better to consolidate to 3 categories each.\n",
    "\n",
    "Balance = <-2, -2 to +2, <+2\n",
    "Logic = if balance > 2 on consistent basis then in one week station is empty or 'clogged'\n",
    "\n",
    "Turnover <0,5 , 0,5 - 2,5 , >2,5\n",
    "Logic = 3-4 as upper limit (we want bikes to be used more than once during the day...)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by station and season the cumulative BALANCE for all days and sort results from lowest to highest value\n",
    "df_cumulative_balance_season = df_2_unique.groupby(['STATION', 'SEASON', 'LAT', 'LNG'])['BALANCE'].sum().reset_index().sort_values(by='BALANCE')\n",
    "df_cumulative_balance_season.rename(columns={'BALANCE': 'CUMULATIVE_BALANCE'}, inplace=True)\n",
    "df_cumulative_balance_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the order of seasons and their corresponding colors\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_colors = {'Winter': 'blue', 'Spring': 'green', 'Summer': 'orange', 'Fall': 'brown'}\n",
    "\n",
    "# Select the top 25 stations with the highest cumulative balance\n",
    "top_25_stations = df_cumulative_balance.nlargest(25, 'CUMULATIVE_BALANCE')['STATION']\n",
    "\n",
    "# Filter the df_cumulative_balance_season DataFrame to include only the top 25 stations\n",
    "df_top_25_season = df_cumulative_balance_season[df_cumulative_balance_season['STATION'].isin(top_25_stations)]\n",
    "\n",
    "# Pivot the DataFrame to have seasons as columns and stations as rows\n",
    "df_pivot = df_top_25_season.pivot(index='STATION', columns='SEASON', values='CUMULATIVE_BALANCE')\n",
    "\n",
    "# Reindex the columns to ensure the correct order of seasons\n",
    "df_pivot = df_pivot[season_order]\n",
    "\n",
    "# Sort the DataFrame by the cumulative balance per year\n",
    "df_pivot = df_pivot.loc[top_25_stations]\n",
    "\n",
    "# Plot the data with reversed season order\n",
    "ax = df_pivot[season_order[::-1]].plot(kind='barh', figsize=(10, 10), color=[season_colors[season] for season in season_order[::-1]])\n",
    "plt.title('Top 25 Stations with Highest Cumulative Balance by Season')\n",
    "plt.xlabel('Cumulative Balance')\n",
    "plt.ylabel('Station')\n",
    "plt.legend(title='Season')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the order of seasons and their corresponding colors\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_colors = {'Winter': 'blue', 'Spring': 'green', 'Summer': 'orange', 'Fall': 'brown'}\n",
    "\n",
    "# Select the top 30 stations with the highest cumulative balance\n",
    "top_30_stations = df_cumulative_balance.nlargest(30, 'CUMULATIVE_BALANCE')['STATION']\n",
    "\n",
    "# Filter the df_cumulative_balance_season DataFrame to include only the top 25 stations\n",
    "df_top_30_season = df_cumulative_balance_season[df_cumulative_balance_season['STATION'].isin(top_30_stations)]\n",
    "\n",
    "# Pivot the DataFrame to have seasons as columns and stations as rows\n",
    "df_pivot = df_top_30_season.pivot(index='STATION', columns='SEASON', values='CUMULATIVE_BALANCE')\n",
    "\n",
    "# Reindex the columns to ensure the correct order of seasons\n",
    "df_pivot = df_pivot[season_order]\n",
    "\n",
    "# Sort the DataFrame by the cumulative balance per year\n",
    "df_pivot = df_pivot.loc[top_30_stations]\n",
    "\n",
    "# Plot the data with reversed season order\n",
    "ax = df_pivot[season_order[::-1]].plot(kind='barh', figsize=(10, 10), color=[season_colors[season] for season in season_order[::-1]])\n",
    "plt.title('Top 30 Stations with Highest Cumulative Balance by Season')\n",
    "plt.xlabel('Cumulative Balance')\n",
    "plt.ylabel('Station')\n",
    "plt.legend(title='Season')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the order of seasons and their corresponding colors\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_colors = {'Winter': 'blue', 'Spring': 'green', 'Summer': 'orange', 'Fall': 'brown'}\n",
    "\n",
    "# Select the 30 stations with the smallest cumulative balance\n",
    "bottom_30_stations = df_cumulative_balance.nsmallest(30, 'CUMULATIVE_BALANCE')['STATION']\n",
    "\n",
    "# Filter the df_cumulative_balance_season DataFrame to include only the bottom 30 stations\n",
    "df_bottom_30_season = df_cumulative_balance_season[df_cumulative_balance_season['STATION'].isin(bottom_30_stations)]\n",
    "\n",
    "# Pivot the DataFrame to have seasons as columns and stations as rows\n",
    "df_pivot = df_bottom_30_season.pivot(index='STATION', columns='SEASON', values='CUMULATIVE_BALANCE')\n",
    "\n",
    "# Reindex the columns to ensure the correct order of seasons\n",
    "df_pivot = df_pivot[season_order]\n",
    "\n",
    "# Sort the DataFrame by the cumulative balance per year\n",
    "df_pivot = df_pivot.loc[bottom_30_stations]\n",
    "\n",
    "# Plot the data with reversed season order\n",
    "ax = df_pivot[season_order[::-1]].plot(kind='barh', figsize=(10, 10), color=[season_colors[season] for season in season_order[::-1]])\n",
    "plt.title('Bottom 30 Stations with Smallest Cumulative Balance by Season')\n",
    "plt.xlabel('Cumulative Balance')\n",
    "plt.ylabel('Station')\n",
    "plt.legend(title='Season')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the order of seasons and their corresponding colors\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "season_colors = {'Winter': 'blue', 'Spring': 'green', 'Summer': 'orange', 'Fall': 'brown'}\n",
    "\n",
    "# Select the top 30 and bottom 30 stations with the highest and smallest cumulative balance\n",
    "top_30_stations = df_cumulative_balance.nlargest(30, 'CUMULATIVE_BALANCE')['STATION']\n",
    "bottom_30_stations = df_cumulative_balance.nsmallest(30, 'CUMULATIVE_BALANCE')['STATION']\n",
    "\n",
    "# Filter the df_cumulative_balance_season DataFrame to include only the top 30 and bottom 30 stations\n",
    "df_top_30_season = df_cumulative_balance_season[df_cumulative_balance_season['STATION'].isin(top_30_stations)]\n",
    "df_bottom_30_season = df_cumulative_balance_season[df_cumulative_balance_season['STATION'].isin(bottom_30_stations)]\n",
    "\n",
    "# Combine the top 30 and bottom 30 dataframes\n",
    "df_combined_season = pd.concat([df_top_30_season, df_bottom_30_season])\n",
    "\n",
    "# Pivot the DataFrame to have seasons as columns and stations as rows\n",
    "df_pivot = df_combined_season.pivot(index='STATION', columns='SEASON', values='CUMULATIVE_BALANCE')\n",
    "\n",
    "# Reindex the columns to ensure the correct order of seasons\n",
    "df_pivot = df_pivot[season_order]\n",
    "\n",
    "# Sort the DataFrame by the cumulative balance per year\n",
    "df_pivot = df_pivot.loc[bottom_30_stations.tolist() + top_30_stations.tolist()]\n",
    "\n",
    "# Plot the data with reversed season order\n",
    "fig, ax1 = plt.subplots(figsize=(12, 15))\n",
    "\n",
    "# Plot bottom 30 stations\n",
    "df_pivot.loc[bottom_30_stations, season_order[::-1]].plot(kind='barh', ax=ax1, color=[season_colors[season] for season in season_order[::-1]], legend=False)\n",
    "ax1.set_ylabel('Bottom 30 Stations')\n",
    "ax1.set_xlabel('Cumulative Balance')\n",
    "\n",
    "# Create a second y-axis for the top 30 stations\n",
    "ax2 = ax1.twinx()\n",
    "df_pivot.loc[top_30_stations, season_order[::-1]].plot(kind='barh', ax=ax2, color=[season_colors[season] for season in season_order[::-1]], legend=False)\n",
    "ax2.set_ylabel('Top 30 Stations')\n",
    "ax2.set_yticks(ax1.get_yticks())\n",
    "ax2.set_yticklabels(top_30_stations)\n",
    "\n",
    "# Add a vertical line at X-Axis = 0\n",
    "ax1.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# Set the title and legend\n",
    "plt.title('Top 30 and Bottom 30 Stations with Cumulative Balance by Season')\n",
    "ax1.legend(title='Season', loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This map uses adjusted scale for each season\n",
    "\n",
    "# Create a base map\n",
    "m4 = folium.Map(location=[df_cumulative_balance_season['LAT'].mean(), df_cumulative_balance_season['LNG'].mean()], zoom_start=12)\n",
    "\n",
    "# Function to determine color based on balance\n",
    "def get_color(balance):\n",
    "    if balance > 0:\n",
    "        return 'blue'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "# Function to add stations to a feature group\n",
    "def add_stations_to_group(group, stations, color, max_balance):\n",
    "    for _, row in stations.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['LAT'], row['LNG']],\n",
    "            radius=1 + (abs(row['CUMULATIVE_BALANCE']) / max_balance) * 10,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Station: {row['STATION']}\\nBalance: {row['CUMULATIVE_BALANCE']}\"\n",
    "        ).add_to(group)\n",
    "\n",
    "# Create feature groups for each season\n",
    "seasons = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "feature_groups = {season: folium.FeatureGroup(name=season, show=(season == 'Summer')) for season in seasons}\n",
    "\n",
    "# Add stations to each feature group\n",
    "for season in seasons:\n",
    "    season_stations = df_cumulative_balance_season[df_cumulative_balance_season['SEASON'] == season]\n",
    "    \n",
    "    # Create dataframes for top 50, bottom 50, and the rest\n",
    "    top_50_stations = season_stations.nlargest(50, 'CUMULATIVE_BALANCE')\n",
    "    bottom_50_stations = season_stations.nsmallest(50, 'CUMULATIVE_BALANCE')\n",
    "    remaining_stations = season_stations[~season_stations['STATION'].isin(top_50_stations['STATION']) & ~season_stations['STATION'].isin(bottom_50_stations['STATION'])]\n",
    "    \n",
    "    # Calculate max balance for scaling\n",
    "    max_balance = max(abs(season_stations['CUMULATIVE_BALANCE'].max()), abs(season_stations['CUMULATIVE_BALANCE'].min()))\n",
    "    \n",
    "    # Add stations to the feature group\n",
    "    add_stations_to_group(feature_groups[season], top_50_stations, 'blue', max_balance)\n",
    "    add_stations_to_group(feature_groups[season], bottom_50_stations, 'red', max_balance)\n",
    "    add_stations_to_group(feature_groups[season], remaining_stations, 'green', max_balance)\n",
    "\n",
    "# Add feature groups to the map\n",
    "for season, group in feature_groups.items():\n",
    "    group.add_to(m4)\n",
    "\n",
    "# Add layer control to switch between seasons\n",
    "folium.LayerControl(collapsed=False).add_to(m4)\n",
    "\n",
    "# Display the map\n",
    "m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This map uses same scale for all seasons\n",
    "\n",
    "\n",
    "# Create a base map\n",
    "m5 = folium.Map(location=[df_cumulative_balance_season['LAT'].mean(), df_cumulative_balance_season['LNG'].mean()], zoom_start=12)\n",
    "\n",
    "# Function to determine color based on balance\n",
    "def get_color(balance):\n",
    "    if balance > 0:\n",
    "        return 'blue'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "# Function to add stations to a feature group\n",
    "def add_stations_to_group(group, stations, color, max_balance):\n",
    "    for _, row in stations.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['LAT'], row['LNG']],\n",
    "            radius=1 + (abs(row['CUMULATIVE_BALANCE']) / max_balance) * 10,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Station: {row['STATION']}\\nBalance: {row['CUMULATIVE_BALANCE']}\"\n",
    "        ).add_to(group)\n",
    "\n",
    "# Create feature groups for each season\n",
    "seasons = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "feature_groups = {season: folium.FeatureGroup(name=season, show=(season == 'Summer')) for season in seasons}\n",
    "\n",
    "# Add stations to each feature group\n",
    "for season in seasons:\n",
    "    season_stations = df_cumulative_balance_season[df_cumulative_balance_season['SEASON'] == season]\n",
    "    \n",
    "    # Create dataframes for top 50, bottom 50, and the rest\n",
    "    top_50_stations = season_stations.nlargest(50, 'CUMULATIVE_BALANCE')\n",
    "    bottom_50_stations = season_stations.nsmallest(50, 'CUMULATIVE_BALANCE')\n",
    "    remaining_stations = season_stations[~season_stations['STATION'].isin(top_50_stations['STATION']) & ~season_stations['STATION'].isin(bottom_50_stations['STATION'])]\n",
    "    \n",
    "    # Calculate max balance for scaling\n",
    "    max_balance = max(abs(df_cumulative_balance_season['CUMULATIVE_BALANCE'].max()), abs(df_cumulative_balance_season['CUMULATIVE_BALANCE'].min()))\n",
    "    \n",
    "    # Add stations to the feature group\n",
    "    add_stations_to_group(feature_groups[season], top_50_stations, 'blue', max_balance)\n",
    "    add_stations_to_group(feature_groups[season], bottom_50_stations, 'red', max_balance)\n",
    "    add_stations_to_group(feature_groups[season], remaining_stations, 'green', max_balance)\n",
    "\n",
    "# Add feature groups to the map\n",
    "for season, group in feature_groups.items():\n",
    "    group.add_to(m5)\n",
    "\n",
    "# Add layer control to switch between seasons\n",
    "folium.LayerControl(collapsed=False).add_to(m5)\n",
    "\n",
    "# Display the map\n",
    "m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by station and weekday the cumulative BALANCE for all days and sort results from lowest to highest value\n",
    "df_cumulative_balance_weekday = df_2_unique.groupby(['STATION', 'WEEKDAY', 'LAT', 'LNG'])['BALANCE'].sum().reset_index().sort_values(by='BALANCE')\n",
    "df_cumulative_balance_weekday.rename(columns={'BALANCE': 'CUMULATIVE_BALANCE'}, inplace=True)\n",
    "df_cumulative_balance_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This map uses same scale for all weekdays\n",
    "\n",
    "# Create a base map\n",
    "m6 = folium.Map(location=[df_cumulative_balance_weekday['LAT'].mean(), df_cumulative_balance_weekday['LNG'].mean()], zoom_start=12)\n",
    "\n",
    "# Function to determine color based on balance\n",
    "def get_color(balance):\n",
    "    if balance > 0:\n",
    "        return 'blue'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "# Function to add stations to a feature group\n",
    "def add_stations_to_group(group, stations, color, max_balance):\n",
    "    for _, row in stations.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['LAT'], row['LNG']],\n",
    "            radius=1 + (abs(row['CUMULATIVE_BALANCE']) / max_balance) * 10,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Station: {row['STATION']}\\nBalance: {row['CUMULATIVE_BALANCE']}\"\n",
    "        ).add_to(group)\n",
    "\n",
    "# Create feature groups for each weekday\n",
    "weekdays = ['Yes', 'No']\n",
    "feature_groups = {weekday: folium.FeatureGroup(name=weekday, show=(weekday == 'Yes')) for weekday in weekdays}\n",
    "\n",
    "# Add stations to each feature group\n",
    "for weekday in weekdays:\n",
    "    weekday_stations = df_cumulative_balance_weekday[df_cumulative_balance_weekday['WEEKDAY'] == weekday]\n",
    "    \n",
    "    # Create dataframes for top 50, bottom 50, and the rest\n",
    "    top_50_stations = weekday_stations.nlargest(50, 'CUMULATIVE_BALANCE')\n",
    "    bottom_50_stations = weekday_stations.nsmallest(50, 'CUMULATIVE_BALANCE')\n",
    "    remaining_stations = weekday_stations[~weekday_stations['STATION'].isin(top_50_stations['STATION']) & ~weekday_stations['STATION'].isin(bottom_50_stations['STATION'])]\n",
    "    \n",
    "    # Calculate max balance for scaling\n",
    "    max_balance = max(abs(df_cumulative_balance_weekday['CUMULATIVE_BALANCE'].max()), abs(df_cumulative_balance_weekday['CUMULATIVE_BALANCE'].min()))\n",
    "    \n",
    "    # Add stations to the feature group\n",
    "    add_stations_to_group(feature_groups[weekday], top_50_stations, 'blue', max_balance)\n",
    "    add_stations_to_group(feature_groups[weekday], bottom_50_stations, 'red', max_balance)\n",
    "    add_stations_to_group(feature_groups[weekday], remaining_stations, 'green', max_balance)\n",
    "\n",
    "# Add feature groups to the map\n",
    "for weekday, group in feature_groups.items():\n",
    "    group.add_to(m6)\n",
    "\n",
    "# Add layer control to switch between weekdays\n",
    "folium.LayerControl(collapsed=False).add_to(m6)\n",
    "\n",
    "# Display the map\n",
    "m6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use df_2_unique and add to each line 'member_type'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDA_Marc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
